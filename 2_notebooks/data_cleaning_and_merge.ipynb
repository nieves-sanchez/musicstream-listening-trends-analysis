{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45b1daf3",
   "metadata": {},
   "source": [
    "üéØ**INSERCCI√ìN DE DATOS EN NUESTRA BASE RESONANCE_ANALITYCS MEDIANTE SQL ALQUEMY**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99d02606",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos todo lo necesario\n",
    "\n",
    "import sys\n",
    "import mysql.connector\n",
    "from mysql.connector import errorcode\n",
    "from sqlalchemy import create_engine,FLOAT, VARCHAR, INTEGER, DATE, SmallInteger\n",
    "from sqlalchemy.sql.sqltypes import String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2f91517",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86909587",
   "metadata": {},
   "outputs": [],
   "source": [
    "#üõ∞Ô∏è‚öôÔ∏è Creamos \"la m√°quina\" que nos conecte con la base de datos\n",
    "\n",
    "engine = create_engine(\n",
    "    'mysql+mysqlconnector://root:****@127.0.0.1/resonance_analytics'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4358e306",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------------------------\n",
    "#                       üéµ SPOTIFYüéµ\n",
    "#-----------------------------------------------------------\n",
    "\n",
    "# 1.‚èπÔ∏è Como primer paso, vamos a convertir los CSV limpios a Dataframe:\n",
    "\n",
    "df_spot_pop_alchemy = pd.read_csv(\"../3_data/processed/spotify_tracks_clean/Spotify_pop_clean.csv\")\n",
    "df_spot_rock_alchemy = pd.read_csv(\"../3_data/processed/spotify_tracks_clean/Spotify_rock_clean.csv\")\n",
    "df_spot_chill_alchemy = pd.read_csv(\"../3_data/processed/spotify_tracks_clean/Spotify_chill_clean.csv\")\n",
    "df_spot_latin_alchemy = pd.read_csv(\"../3_data/processed/spotify_tracks_clean/Spotify_latin_clean.csv\")\n",
    "\n",
    "#2.üîÑÔ∏è Renombramos las columnas con la que tenemos conflicto en Workbench, por estar nombradas como palabras reservadas\n",
    "#Este conflicto solamente lo tenemos en los archivos de Spotify.\n",
    "\n",
    "df_spot_pop_rename= df_spot_pop_alchemy.rename(columns={\"year\":\"release_year\", \"type\":\"type_info\"})\n",
    "df_spot_rock_rename= df_spot_rock_alchemy.rename(columns={\"year\":\"release_year\", \"type\":\"type_info\"})\n",
    "df_spot_chill_rename= df_spot_chill_alchemy.rename(columns={\"year\": \"release_year\", \"type\":\"type_info\"})\n",
    "df_spot_latin_rename= df_spot_latin_alchemy.rename(columns={\"year\": \"release_year\", \"type\":\"type_info\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f40b8302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_track</th>\n",
       "      <th>artist_name_raw</th>\n",
       "      <th>artist_name_norm</th>\n",
       "      <th>name_album</th>\n",
       "      <th>type_info</th>\n",
       "      <th>release_year</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>popularity</th>\n",
       "      <th>id_genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cristina</td>\n",
       "      <td>Sebastian Yatra</td>\n",
       "      <td>sebastian yatra</td>\n",
       "      <td>FANTAS√çA</td>\n",
       "      <td>track</td>\n",
       "      <td>2019</td>\n",
       "      <td>201626</td>\n",
       "      <td>72</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LA CANCI√ìN</td>\n",
       "      <td>J Balvin</td>\n",
       "      <td>j balvin</td>\n",
       "      <td>OASIS</td>\n",
       "      <td>track</td>\n",
       "      <td>2019</td>\n",
       "      <td>242573</td>\n",
       "      <td>89</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   name_track  artist_name_raw artist_name_norm name_album type_info  \\\n",
       "0    Cristina  Sebastian Yatra  sebastian yatra   FANTAS√çA     track   \n",
       "1  LA CANCI√ìN         J Balvin         j balvin      OASIS     track   \n",
       "\n",
       "   release_year  duration_ms  popularity  id_genre  \n",
       "0          2019       201626          72         4  \n",
       "1          2019       242573          89         4  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comprobamos que el renombrado de columnas es el esperado.\n",
    "df_spot_latin_rename.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92801160",
   "metadata": {},
   "outputs": [],
   "source": [
    "''''üßπBORRADO DE DUPLICADOS: Aunque en la extracci√≥n de datos ya se contempl√≥ el borrado de duplicados, debido al uso del m√©todo search del API \n",
    "de Spotify y a no usar el ID propio de este, vamos a hacer una segunda limpieza de datos de modo que: \n",
    "    misma canci√≥n + artista + a√±o en el mismo g√©nero ‚Üí si aparece repetida, se limpia'''\n",
    "\n",
    "#--------------------- POP -----------------------------------\n",
    "print(\"Limpiando canciones Pop\")\n",
    "print(\"Antes:\", len(df_spot_pop_rename))\n",
    "df_pop_sin_dup = df_spot_pop_rename.drop_duplicates(subset=[\"name_track\", \"artist_name_norm\", \"release_year\",\"id_genre\"], keep=\"first\").reset_index(drop=True)\n",
    "print(\"Despu√©s:\", len(df_pop_sin_dup))\n",
    "print(\"Duplicados eliminados:\", len(df_spot_pop_rename) - len(df_pop_sin_dup))\n",
    "\n",
    "# Comprobaci√≥n: deber√≠a ser 0\n",
    "print(\"Duplicados restantes:\", df_pop_sin_dup.duplicated(\n",
    "    subset=[\"name_track\", \"artist_name_norm\", \"release_year\", \"id_genre\"]\n",
    ").sum())\n",
    "print(\"-\"*20)\n",
    " #--------------------- ROCK ---------------------------------\n",
    "print(\"Limpiando canciones Rock\")\n",
    "print(\"Antes:\", len(df_spot_rock_rename))\n",
    "df_rock_sin_dup = df_spot_rock_rename.drop_duplicates(subset=[\"name_track\", \"artist_name_norm\", \"release_year\", \"id_genre\"], keep=\"first\").reset_index(drop = True)\n",
    "print(\"Despu√©s:\", len(df_rock_sin_dup))\n",
    "print(\"Duplicados eliminados:\", len(df_spot_rock_rename) - len(df_rock_sin_dup))\n",
    "\n",
    "# Comprobaci√≥n: deber√≠a ser 0\n",
    "print(\"Duplicados restantes:\", df_rock_sin_dup.duplicated(\n",
    "    subset=[\"name_track\", \"artist_name_norm\", \"release_year\", \"id_genre\"]\n",
    ").sum())\n",
    "print(\"-\"*20)\n",
    "#----------------------- CHILL ----------------------------------\n",
    "print(\"Limpiando canciones Chill\")\n",
    "print(\"Antes:\", len(df_spot_chill_rename))\n",
    "df_chill_sin_dup = df_spot_chill_rename.drop_duplicates(subset=[\"name_track\", \"artist_name_norm\", \"release_year\", \"id_genre\"], keep=\"first\").reset_index(drop = True)\n",
    "print(\"Despu√©s:\", len(df_chill_sin_dup))\n",
    "print(\"Duplicados eliminados:\", len(df_spot_chill_rename) - len(df_chill_sin_dup))\n",
    "\n",
    "# Comprobaci√≥n: deber√≠a ser 0\n",
    "print(\"Duplicados restantes:\", df_chill_sin_dup.duplicated(\n",
    "    subset=[\"name_track\", \"artist_name_norm\", \"release_year\", \"id_genre\"]\n",
    ").sum())\n",
    "print(\"-\"*20)\n",
    "#------------------------ LATIN ---------------------------------\n",
    "print(\"Limpiando cancines Latin\")\n",
    "print(\"Antes:\", len(df_spot_latin_rename))\n",
    "df_latin_sin_dup = df_spot_latin_rename.drop_duplicates(subset=[\"name_track\", \"artist_name_norm\", \"release_year\", \"id_genre\"], keep=\"first\").reset_index(drop = True)\n",
    "print(\"Despu√©s:\", len(df_latin_sin_dup))\n",
    "print(\"Duplicados eliminados:\", len(df_spot_latin_rename) - len(df_latin_sin_dup))\n",
    "\n",
    "# Comprobaci√≥n: deber√≠a ser 0\n",
    "print(\"Duplicados restantes:\", df_latin_sin_dup.duplicated(\n",
    "    subset=[\"name_track\", \"artist_name_norm\", \"release_year\", \"id_genre\"]\n",
    ").sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae601d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------------\n",
    "#                       üéôÔ∏èLAST FMüéôÔ∏è\n",
    "#---------------------------------------------------------\n",
    "\n",
    "#1.‚èπÔ∏è Del mismo modo que hicimos con los ficheros de Spotify, leemos y guardamos como Dataframe los de Last.FM\n",
    "\n",
    "df_last_pop_mysql = pd.read_csv(\"../3_data/raw/lastfm_artists/lastfm_info_artists_pop.csv\")\n",
    "df_last_rock_mysql = pd.read_csv(\"../3_data/raw/lastfm_artists/lastfm_info_artists_rock.csv\")\n",
    "df_last_chill_mysql = pd.read_csv(\"../3_data/raw/lastfm_artists/lastfm_info_artists_chill.csv\")\n",
    "df_last_latin_mysql = pd.read_csv(\"../3_data/raw/lastfm_artists/lastfm_info_artists_latin.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b972f056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_name_raw</th>\n",
       "      <th>artist_name_norm</th>\n",
       "      <th>listeners</th>\n",
       "      <th>playcount</th>\n",
       "      <th>id_genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2 Minutos</td>\n",
       "      <td>2 minutos</td>\n",
       "      <td>71336</td>\n",
       "      <td>2507334</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24kGoldn</td>\n",
       "      <td>24kgoldn</td>\n",
       "      <td>1164983</td>\n",
       "      <td>22573449</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60 juno</td>\n",
       "      <td>60 juno</td>\n",
       "      <td>229155</td>\n",
       "      <td>1770362</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  artist_name_raw artist_name_norm  listeners  playcount  id_genre\n",
       "0       2 Minutos        2 minutos      71336    2507334         2\n",
       "1        24kGoldn         24kgoldn    1164983   22573449         2\n",
       "2         60 juno          60 juno     229155    1770362         2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2.üïµüèª‚Äç‚ôÄÔ∏è Vamos a hacer alguna sencilla comprobaci√≥n del resultado obtenido.\n",
    "df_last_rock_mysql.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2685d412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Limpiando artistas Pop\n",
      "Antes: 351\n",
      "Despu√©s: 350\n",
      "Duplicados eliminados: 1\n",
      "Duplicados restantes: 0\n",
      "--------------------\n",
      "Limpiando artistas Rock\n",
      "Antes: 470\n",
      "Despu√©s: 469\n",
      "Duplicados eliminados: 1\n",
      "Duplicados restantes: 0\n",
      "--------------------\n",
      "Limpiando artistas Chill\n",
      "Antes: 166\n",
      "Despu√©s: 166\n",
      "Duplicados eliminados: 0\n",
      "Duplicados restantes: 0\n",
      "--------------------\n",
      "Limpiando artistas Latin\n",
      "Antes: 265\n",
      "Despu√©s: 265\n",
      "Duplicados eliminados: 0\n",
      "Duplicados restantes: 0\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "''''üßπ BORRADO DE DUPLICADOS DE LOS CSV de LAST FM:'''\n",
    "\n",
    "#--------------------- POP -----------------------------------\n",
    "print(\"Limpiando artistas Pop\")\n",
    "print(\"Antes:\", len(df_last_pop_mysql))\n",
    "df_last_pop_sin_dup = df_last_pop_mysql.drop_duplicates(subset=[ \"artist_name_raw\", \"artist_name_norm\",\"listeners\" ,\"playcount\",\"id_genre\"], keep=\"first\").reset_index(drop=True)\n",
    "print(\"Despu√©s:\", len(df_last_pop_sin_dup))\n",
    "print(\"Duplicados eliminados:\", len(df_last_pop_mysql) - len(df_last_pop_sin_dup))\n",
    "\n",
    "# Comprobaci√≥n: deber√≠a ser 0\n",
    "print(\"Duplicados restantes:\", df_last_pop_sin_dup.duplicated(\n",
    "    subset=[\"artist_name_raw\", \"artist_name_norm\",\"listeners\" ,\"playcount\",\"id_genre\"]\n",
    ").sum())\n",
    "print(\"-\"*20)\n",
    "\n",
    "# Guardar CSV limpio\n",
    "df_last_pop_sin_dup.to_csv('../3_data/processed/lastfm_artist_clean/last_info_artists_pop_clean.csv', index=False)\n",
    "\n",
    " #--------------------- ROCK ---------------------------------\n",
    "print(\"Limpiando artistas Rock\")\n",
    "print(\"Antes:\", len(df_last_rock_mysql))\n",
    "df_last_rock_sin_dup = df_last_rock_mysql.drop_duplicates(subset=[ \"artist_name_raw\", \"artist_name_norm\",\"listeners\" ,\"playcount\",\"id_genre\"], keep=\"first\").reset_index(drop=True)\n",
    "print(\"Despu√©s:\", len(df_last_rock_sin_dup))\n",
    "print(\"Duplicados eliminados:\", len(df_last_rock_mysql) - len(df_last_rock_sin_dup))\n",
    "\n",
    "# Comprobaci√≥n: deber√≠a ser 0\n",
    "print(\"Duplicados restantes:\", df_last_rock_sin_dup.duplicated(\n",
    "    subset=[\"artist_name_raw\", \"artist_name_norm\",\"listeners\" ,\"playcount\",\"id_genre\"]\n",
    ").sum())\n",
    "print(\"-\"*20)\n",
    "\n",
    "# Guardar CSV limpio\n",
    "df_last_rock_sin_dup.to_csv('../3_data/processed/lastfm_artist_clean/last_info_artists_rock_clean.csv', index=False)\n",
    "\n",
    "#----------------------- CHILL ----------------------------------\n",
    "print(\"Limpiando artistas Chill\")\n",
    "print(\"Antes:\", len(df_last_chill_mysql))\n",
    "df_last_chill_sin_dup = df_last_chill_mysql.drop_duplicates(subset=[ \"artist_name_raw\", \"artist_name_norm\",\"listeners\" ,\"playcount\",\"id_genre\"], keep=\"first\").reset_index(drop=True)\n",
    "print(\"Despu√©s:\", len(df_last_chill_sin_dup))\n",
    "print(\"Duplicados eliminados:\", len(df_last_chill_mysql) - len(df_last_chill_sin_dup))\n",
    "\n",
    "# Comprobaci√≥n: deber√≠a ser 0\n",
    "print(\"Duplicados restantes:\", df_last_chill_sin_dup.duplicated(\n",
    "    subset=[\"artist_name_raw\", \"artist_name_norm\",\"listeners\" ,\"playcount\",\"id_genre\"]\n",
    ").sum())\n",
    "print(\"-\"*20)\n",
    "\n",
    "# Guardar CSV limpio\n",
    "df_last_chill_sin_dup.to_csv('../3_data/processed/lastfm_artist_clean/last_info_artists_chill_clean.csv', index=False)\n",
    "\n",
    "#------------------------ LATIN ---------------------------------\n",
    "print(\"Limpiando artistas Latin\")\n",
    "print(\"Antes:\", len(df_last_latin_mysql))\n",
    "df_last_latin_sin_dup = df_last_latin_mysql.drop_duplicates(subset=[ \"artist_name_raw\", \"artist_name_norm\",\"listeners\" ,\"playcount\",\"id_genre\"], keep=\"first\").reset_index(drop=True)\n",
    "print(\"Despu√©s:\", len(df_last_latin_sin_dup))\n",
    "print(\"Duplicados eliminados:\", len(df_last_latin_mysql) - len(df_last_latin_sin_dup))\n",
    "\n",
    "# Comprobaci√≥n: deber√≠a ser 0\n",
    "print(\"Duplicados restantes:\", df_last_latin_sin_dup.duplicated(\n",
    "    subset=[\"artist_name_raw\", \"artist_name_norm\",\"listeners\" ,\"playcount\",\"id_genre\"]\n",
    ").sum())\n",
    "print(\"-\"*20)\n",
    "\n",
    "# Guardar CSV limpio\n",
    "df_last_latin_sin_dup.to_csv('../3_data/processed/lastfm_artist_clean/last_info_artists_latin_clean.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b54050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artistas en canciones pero no en tabla artistas: 43\n"
     ]
    }
   ],
   "source": [
    "# Revisamos si hay nombres de artistas que no coincidir√°n\n",
    "artistas_en_canciones = set(df_pop_sin_dup['artist_name_norm'].unique())\n",
    "artistas_en_tabla_artistas = set(df_last_pop_sin_dup['artist_name_norm'].unique())\n",
    "\n",
    "print(f\"Artistas en canciones pero no en tabla artistas: {len(artistas_en_canciones - artistas_en_tabla_artistas)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f7c27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apoy√°ndonos en la IA, observamos problemas de normalizaci√≥n. Vamos a re-normalizar ambas extracciones (Spotify/LastFM)\n",
    "# pues tras el limpiado de los archivos de Last.FM, hay 43 artistas en canciones que no figuran en los datos\n",
    "# de artistas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2542e99d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "PROCESANDO: POP\n",
      "============================================================\n",
      "Total canciones: 913\n",
      "Artistas √∫nicos en canciones: 351\n",
      "Artistas √∫nicos en tabla artistas: 350\n",
      "Artistas faltantes: 4\n",
      "Canciones afectadas: 5 (0.55%)\n",
      "\n",
      "Artistas faltantes: ['babymonster', 'cali y el dandee', 'l a x', 'noah cyrus']\n",
      "\n",
      "============================================================\n",
      "PROCESANDO: ROCK\n",
      "============================================================\n",
      "Total canciones: 945\n",
      "Artistas √∫nicos en canciones: 470\n",
      "Artistas √∫nicos en tabla artistas: 469\n",
      "Artistas faltantes: 5\n",
      "Canciones afectadas: 11 (1.16%)\n",
      "\n",
      "Artistas faltantes: ['bayronn caicedo', 'bunbury', 'the goo goo dolls', 'thirty seconds to mars', 'tk from ling tosite sigure']\n",
      "\n",
      "============================================================\n",
      "PROCESANDO: CHILL\n",
      "============================================================\n",
      "Total canciones: 667\n",
      "Artistas √∫nicos en canciones: 166\n",
      "Artistas √∫nicos en tabla artistas: 166\n",
      "Artistas faltantes: 0\n",
      "‚úì Todos los artistas tienen coincidencia perfecta\n",
      "\n",
      "============================================================\n",
      "PROCESANDO: LATIN\n",
      "============================================================\n",
      "Total canciones: 932\n",
      "Artistas √∫nicos en canciones: 265\n",
      "Artistas √∫nicos en tabla artistas: 265\n",
      "Artistas faltantes: 1\n",
      "Canciones afectadas: 1 (0.11%)\n",
      "\n",
      "Artistas faltantes: ['hugel']\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "\n",
    "def normalizar_artista_consistente(nombre):\n",
    "    \"\"\"\n",
    "    Normaliza nombres de artistas de forma consistente:\n",
    "    - Min√∫sculas\n",
    "    - Sin tildes/acentos\n",
    "    - Sin caracteres especiales (excepto espacios y guiones)\n",
    "    \"\"\"\n",
    "    if pd.isna(nombre):\n",
    "        return nombre\n",
    "    \n",
    "    nombre = nombre.lower()\n",
    "    \n",
    "    # Eliminar tildes y acentos\n",
    "    nombre = ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', nombre)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "    \n",
    "    # Eliminar caracteres especiales excepto espacios, guiones y letras\n",
    "    nombre = ''.join(c if c.isalnum() or c in ' -' else ' ' for c in nombre)\n",
    "    \n",
    "    # Normalizar espacios m√∫ltiples\n",
    "    nombre = ' '.join(nombre.split())\n",
    "    \n",
    "    return nombre.strip()\n",
    "\n",
    "\n",
    "def procesar_canciones_y_artistas(df_canciones, df_artistas, nombre_genero=\"\"):\n",
    "    \"\"\"\n",
    "    Normaliza y verifica coincidencias entre dataframes de canciones y artistas.\n",
    "    \n",
    "    Par√°metros:\n",
    "    - df_canciones: DataFrame con columnas 'artist_name_raw' y 'artist_name_norm'\n",
    "    - df_artistas: DataFrame con columnas 'artist_name_raw' y 'artist_name_norm'\n",
    "    - nombre_genero: String opcional para identificar el g√©nero en los prints\n",
    "    \n",
    "    Retorna:\n",
    "    - df_canciones normalizado\n",
    "    - df_artistas normalizado\n",
    "    - set de artistas faltantes\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"PROCESANDO: {nombre_genero if nombre_genero else 'G√©nero'}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Re-normalizar ambos dataframes\n",
    "    df_canciones['artist_name_norm'] = df_canciones['artist_name_raw'].apply(normalizar_artista_consistente)\n",
    "    df_artistas['artist_name_norm'] = df_artistas['artist_name_raw'].apply(normalizar_artista_consistente)\n",
    "    \n",
    "    # Verificar coincidencias\n",
    "    artistas_en_canciones = set(df_canciones['artist_name_norm'].unique())\n",
    "    artistas_en_tabla_artistas = set(df_artistas['artist_name_norm'].unique())\n",
    "    artistas_faltantes = artistas_en_canciones - artistas_en_tabla_artistas\n",
    "    \n",
    "    # Reportar resultados\n",
    "    print(f\"Total canciones: {len(df_canciones)}\")\n",
    "    print(f\"Artistas √∫nicos en canciones: {len(artistas_en_canciones)}\")\n",
    "    print(f\"Artistas √∫nicos en tabla artistas: {len(artistas_en_tabla_artistas)}\")\n",
    "    print(f\"Artistas faltantes: {len(artistas_faltantes)}\")\n",
    "    \n",
    "    if len(artistas_faltantes) > 0:\n",
    "        canciones_huerfanas = df_canciones[df_canciones['artist_name_norm'].isin(artistas_faltantes)]\n",
    "        porcentaje = len(canciones_huerfanas)/len(df_canciones)*100\n",
    "        print(f\"Canciones afectadas: {len(canciones_huerfanas)} ({porcentaje:.2f}%)\")\n",
    "        print(f\"\\nArtistas faltantes: {sorted(list(artistas_faltantes))}\")\n",
    "    else:\n",
    "        print(\"‚úì Todos los artistas tienen coincidencia perfecta\")\n",
    "    \n",
    "    return df_canciones, df_artistas, artistas_faltantes\n",
    "\n",
    "\n",
    "# USO:\n",
    "# Para g√©nero Pop\n",
    "df_pop_sin_dup, df_last_pop_sin_dup, faltantes_pop = procesar_canciones_y_artistas(\n",
    "    df_pop_sin_dup, \n",
    "    df_last_pop_sin_dup,  \n",
    "    \"POP\"\n",
    ")\n",
    "\n",
    "# Para g√©nero Rock (ejemplo)\n",
    "df_rock_sin_dup, df_last_rock_sin_dup, faltantes_rock = procesar_canciones_y_artistas(\n",
    "    df_rock_sin_dup, \n",
    "    df_last_rock_sin_dup,\n",
    "    \"ROCK\"\n",
    ")\n",
    "\n",
    "# Para g√©nero Chill (ejemplo)\n",
    "df_chill_sin_dup, df_last_chill_sin_dup, faltantes_chill = procesar_canciones_y_artistas(\n",
    "    df_chill_sin_dup, \n",
    "    df_last_chill_sin_dup,\n",
    "    \"CHILL\"\n",
    ")\n",
    "\n",
    "# Para g√©nero Latin (ejemplo)\n",
    "df_latin_sin_dup, df_last_latin_sin_dup, faltantes_latin = procesar_canciones_y_artistas(\n",
    "    df_latin_sin_dup, \n",
    "    df_last_latin_sin_dup,\n",
    "    \"LATIN\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9127cbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''Vamos a \"manejar\" diez artistas faltantes. Para ello, vamos a filtrar las canciones hu√©rfanas \n",
    "antes de cargar a Workbench (recomendado por el bajo impacto):''' \n",
    "\n",
    "# Aplicar a cada g√©nero\n",
    "df_pop_final = df_pop_sin_dup[\n",
    "    df_pop_sin_dup['artist_name_norm'].isin(set(df_last_pop_sin_dup['artist_name_norm']))\n",
    "]\n",
    "\n",
    "df_rock_final = df_rock_sin_dup[\n",
    "    df_rock_sin_dup['artist_name_norm'].isin(set(df_last_rock_sin_dup['artist_name_norm']))\n",
    "]\n",
    "\n",
    "df_latin_final = df_latin_sin_dup[\n",
    "    df_latin_sin_dup['artist_name_norm'].isin(set(df_last_latin_sin_dup['artist_name_norm']))\n",
    "]\n",
    "\n",
    "# Chill ya est√° perfecto, no necesitas filtrarlo\n",
    "\n",
    "# Guardar las versiones finales\n",
    "df_pop_final.to_csv('../3_data/processed/final/tracks_pop_final.csv', index=False, encoding='utf-8')\n",
    "df_rock_final.to_csv('../3_data/processed/final/tracks_rock_final.csv', index=False, encoding='utf-8')\n",
    "df_latin_final.to_csv('../3_data/processed/final/tracks_latin_final.csv', index=False, encoding='utf-8')\n",
    "df_chill_sin_dup.to_csv('../3_data/processed/final/tracks_chill_final.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b045a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos las versiones finales de Last.FM tambi√©n\n",
    "df_last_pop_sin_dup.to_csv('../3_data/processed/final/artists_pop_final.csv', index=False, encoding='utf-8')\n",
    "df_last_rock_sin_dup.to_csv('../3_data/processed/final/artists_rock_final.csv', index=False, encoding='utf-8')\n",
    "df_last_chill_sin_dup.to_csv('../3_data/processed/final/artists_chill_final.csv', index=False, encoding='utf-8')\n",
    "df_last_latin_sin_dup.to_csv('../3_data/processed/final/artists_latin_final.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5ea17e05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "931"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#üöÄ Enviamos los datos de Spotify a la tabla TRACKS que previamente hemos creado en Workbench:\n",
    "\n",
    "df_pop_final.to_sql('tracks', engine, if_exists='append', index=False) \n",
    "df_rock_final.to_sql('tracks', engine, if_exists='append', index=False)\n",
    "df_chill_sin_dup.to_sql('tracks', engine, if_exists='append', index=False)# Este estaba perfecto por lo que no se toca.\n",
    "df_latin_final.to_sql('tracks', engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "30834051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "265"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#üöÄ Enviamos los datos de Last.FM a la tabla ARTISTS que previamente hemos creado en Workbench:\n",
    "\n",
    "df_last_pop_sin_dup.to_sql('artists', engine, if_exists='append', index=False)\n",
    "df_last_rock_sin_dup.to_sql('artists', engine, if_exists='append', index=False)\n",
    "df_last_chill_sin_dup.to_sql('artists', engine, if_exists='append', index=False)\n",
    "df_last_latin_sin_dup.to_sql('artists', engine, if_exists='append', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
